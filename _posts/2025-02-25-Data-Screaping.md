---
title: "ğŸ“Š Dasar-Dasar Data Scraping dengan Python"
date: 2025-02-25T00:00:00.000+00:00
categories: [Data Science, Web Scraping, Python, Data Meaning]
layout: post
author: Pangeran Juhrifar Jafar
permalink: "/daily/3"
tags:
- Data Science
---

## ğŸ§ Apa Itu Data Scraping?

Data Scraping adalah proses otomatis untuk mengambil data dari sebuah website. Teknik ini sangat berguna ketika data yang kita butuhkan tidak tersedia dalam format yang bisa langsung diunduh, seperti CSV atau API.

## ğŸ”„ Alur Dasar Data Scraping

1. **ğŸ¯ Memilih Website Target** â€“ Tentukan website yang ingin diambil datanya.
2. **ğŸ” Memahami Struktur HTML** â€“ Gunakan *Inspect Element* di browser untuk melihat struktur HTML.
3. **ğŸ› ï¸ Menggunakan Pustaka Scraping** â€“ Biasanya menggunakan Python dengan pustaka seperti:
   - ğŸ—ï¸ `BeautifulSoup` untuk parsing HTML
   - ğŸŒ `Requests` untuk mengunduh halaman website
   - ğŸ•·ï¸ `Scrapy` untuk scraping dalam skala besar
4. **ğŸ’¾ Menyimpan Data yang Didapat** â€“ Data yang diambil biasanya disimpan dalam format seperti CSV, JSON, atau database.
5. **ğŸ›¡ï¸ Mengatasi Kendala Scraping** â€“ Beberapa website melarang scraping, jadi butuh strategi seperti rotasi User-Agent, penggunaan proxy, atau Selenium untuk menangani JavaScript.

## ğŸ“œ Logbook Proses Scraping

### **1ï¸âƒ£ Deskripsi Pekerjaan**
ğŸ“ Melakukan web scraping untuk mengambil daftar hari Ramadhan 2025 dari situs Detik.

### **2ï¸âƒ£ Langkah-langkah yang Dilakukan**

#### **ğŸ”— Menentukan Sumber Data**
- ğŸŒ **URL sumber data:** [Detik](https://www.detik.com/jateng/berita/d-7793120/bulan-ramadhan-2025-berapa-hijriah-cek-kalender-dan-tanggalan-islam-tahun-ini)
- ğŸ·ï¸ **Elemen yang akan di-scrape:** Daftar hari Ramadhan (ditemukan dalam tag `<li>`).

#### **ğŸ“© Melakukan Request ke Halaman Web**
- ğŸ“¡ Menggunakan `requests` untuk mengambil halaman HTML.
- ğŸ›¡ï¸ Menambahkan User-Agent agar tidak diblokir oleh situs.

#### **ğŸ§© Parsing HTML dengan BeautifulSoup**
- ğŸ—ï¸ Menggunakan `BeautifulSoup` untuk memproses HTML.
- ğŸ” Mencari semua elemen `<li>` dalam halaman.

#### **ğŸ§¹ Filter Data**
- âœ¨ Membersihkan teks dari `<li>` yang ditemukan.
- ğŸ” Memfilter hanya teks yang mengandung kata "Ramadhan" agar hanya data yang relevan yang diambil.

#### **ğŸ“Œ Menampilkan Hasil**
- ğŸ“œ Mencetak daftar hari Ramadhan yang telah diproses.

### **3ï¸âƒ£ Kode yang Digunakan**
```python
import requests
from bs4 import BeautifulSoup

# Step 1: Request halaman web
url = "https://www.detik.com/jateng/berita/d-7793120/bulan-ramadhan-2025-berapa-hijriah-cek-kalender-dan-tanggalan-islam-tahun-ini"
headers = {"User-Agent": "Mozilla/5.0"}
response = requests.get(url, headers=headers)

# Step 2: Parsing HTML
soup = BeautifulSoup(response.text, "html.parser")

# Step 3: Ambil data yang diinginkan
dates = soup.find_all("li")  # Menyesuaikan dengan struktur HTML

# Step 4: Filter dan cetak hasil
for date in dates:
    if "Ramadhan" in date.text:
        print(date.text.strip())
```
ğŸ’¡ **Kode ini akan mengambil semua elemen `<li>` dari halaman web dan hanya menampilkan yang mengandung kata "Ramadhan".**  

### **4ï¸âƒ£ Hasil yang Diperoleh**
âœ… **Berhasil** mengambil daftar hari Ramadhan dari halaman web.  
âœ… Hanya **data yang relevan** yang diambil dan ditampilkan.  
âœ… **Hasil sesuai** dengan ekspektasi.  

<h3>âš ï¸ Kendala dan Solusi</h3>
<table border="1">
    <tr>
        <th>Kendala</th>
        <th>Solusi</th>
    </tr>
    <tr>
        <td>ğŸŒ Website menggunakan JavaScript</td>
        <td>ğŸ–¥ï¸ Gunakan Selenium untuk mengeksekusi JavaScript sebelum scraping.</td>
    </tr>
    <tr>
        <td>ğŸš« Pemblokiran oleh Website</td>
        <td>ğŸ”„ Gunakan User-Agent yang berbeda atau rotasi proxy.</td>
    </tr>
    <tr>
        <td>ğŸ“Š Data Tidak Terstruktur</td>
        <td>ğŸ› ï¸ Gunakan regex atau metode parsing tambahan untuk membersihkan data.</td>
    </tr>
</table>


## ğŸ”œ Rencana Selanjutnya
- âœ… Mengembangkan kode agar bisa menyimpan hasil scraping dalam file CSV.
- âœ… Menggunakan Selenium jika data ternyata dimuat secara dinamis.
- âœ… Mengotomatiskan proses scraping dan logging.

---

ğŸ“Œ **Catatan:** Logbook ini dapat diperbarui setiap kali ada perkembangan dalam tugas scraping. ğŸš€

